---
title: "Test"
categories: 
  - Blogging
last_modified_at: 2020-09-12
tags:
  - Test
use_math: true
toc: true
---
#### Transformer-layer distillation

* Loss for attention mechanism

\[
y=ax+b
\]

$
y=cx+d
$

* 아아아아ㅏ 테스트 중입니다 
